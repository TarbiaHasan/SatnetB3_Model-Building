{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "692040fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import RandomFlip, RandomRotation, RandomZoom, RandomBrightness\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd59bae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set directory paths\n",
    "train_dir = 'D:/LSCIDMR/Splitting_Augmented/train'\n",
    "val_dir = 'D:/LSCIDMR/Splitting_Augmented/val'\n",
    "test_dir = 'D:/LSCIDMR/Splitting_Augmented/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1082ff9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image dimensions and batch size\n",
    "img_height, img_width = 224, 224\n",
    "batch_size = 16\n",
    "num_classes = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fcf9a36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced data augmentation for the training set\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    RandomFlip(\"horizontal\"),\n",
    "    RandomRotation(0.1),\n",
    "    RandomZoom(0.1),\n",
    "    RandomBrightness(0.1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c17335d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 62979 files belonging to 8 classes.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n"
     ]
    }
   ],
   "source": [
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    label_mode='int'\n",
    ").map(lambda x, y: (data_augmentation(x, training=True), y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3bbb362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7869 files belonging to 8 classes.\n",
      "Found 7880 files belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    val_dir,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    label_mode='int'\n",
    ")\n",
    "\n",
    "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    label_mode='int',\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a1e3800-ea9f-41dd-98a8-8b83aee60aaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7880 files belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    label_mode='int',\n",
    "    shuffle=False  # Ensure the order is preserved\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0823144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the backbone of the model using EfficientNetB3\n",
    "base_model = tf.keras.applications.EfficientNetB3(\n",
    "    input_shape=(img_height, img_width, 3),\n",
    "    include_top=False,\n",
    "    weights='imagenet'\n",
    ")\n",
    "\n",
    "base_model.trainable = True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e0802a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add custom classification layers with Batch Normalization\n",
    "from tensorflow.keras import regularizers\n",
    "model = tf.keras.Sequential([\n",
    "    base_model,\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.GlobalAveragePooling2D(),\n",
    "    tf.keras.layers.Dense(256, activation='relu', \n",
    "                          kernel_regularizer=regularizers.l2(0.01)),  \n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "initial_learning_rate = 0.0005 \n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate,\n",
    "    decay_steps=1000,\n",
    "    decay_rate=0.9,\n",
    "    staircase=True\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4985a81",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "3937/3937 [==============================] - ETA: 0s - loss: 0.7508 - accuracy: 0.8674Epoch 1: Training Loss = 0.7508, Training Accuracy = 0.8674, Validation Loss = 0.2850, Validation Accuracy = 0.9285\n",
      "3937/3937 [==============================] - 1344s 337ms/step - loss: 0.7508 - accuracy: 0.8674 - val_loss: 0.2850 - val_accuracy: 0.9285\n",
      "Epoch 2/30\n",
      "3937/3937 [==============================] - ETA: 0s - loss: 0.3124 - accuracy: 0.9191Epoch 2: Training Loss = 0.3124, Training Accuracy = 0.9191, Validation Loss = 0.2212, Validation Accuracy = 0.9410\n",
      "3937/3937 [==============================] - 1383s 351ms/step - loss: 0.3124 - accuracy: 0.9191 - val_loss: 0.2212 - val_accuracy: 0.9410\n",
      "Epoch 3/30\n",
      "3937/3937 [==============================] - ETA: 0s - loss: 0.2233 - accuracy: 0.9428Epoch 3: Training Loss = 0.2233, Training Accuracy = 0.9428, Validation Loss = 0.1457, Validation Accuracy = 0.9626\n",
      "3937/3937 [==============================] - 1329s 337ms/step - loss: 0.2233 - accuracy: 0.9428 - val_loss: 0.1457 - val_accuracy: 0.9626\n",
      "Epoch 4/30\n",
      "3937/3937 [==============================] - ETA: 0s - loss: 0.1654 - accuracy: 0.9580Epoch 4: Training Loss = 0.1654, Training Accuracy = 0.9580, Validation Loss = 0.1239, Validation Accuracy = 0.9694\n",
      "3937/3937 [==============================] - 1385s 352ms/step - loss: 0.1654 - accuracy: 0.9580 - val_loss: 0.1239 - val_accuracy: 0.9694\n",
      "Epoch 5/30\n",
      "3937/3937 [==============================] - ETA: 0s - loss: 0.1238 - accuracy: 0.9680Epoch 5: Training Loss = 0.1238, Training Accuracy = 0.9680, Validation Loss = 0.1049, Validation Accuracy = 0.9732\n",
      "3937/3937 [==============================] - 1324s 336ms/step - loss: 0.1238 - accuracy: 0.9680 - val_loss: 0.1049 - val_accuracy: 0.9732\n",
      "Epoch 6/30\n",
      "3937/3937 [==============================] - ETA: 0s - loss: 0.0969 - accuracy: 0.9753Epoch 6: Training Loss = 0.0969, Training Accuracy = 0.9753, Validation Loss = 0.0876, Validation Accuracy = 0.9771\n",
      "3937/3937 [==============================] - 1383s 351ms/step - loss: 0.0969 - accuracy: 0.9753 - val_loss: 0.0876 - val_accuracy: 0.9771\n",
      "Epoch 7/30\n",
      "3937/3937 [==============================] - ETA: 0s - loss: 0.0799 - accuracy: 0.9804Epoch 7: Training Loss = 0.0799, Training Accuracy = 0.9804, Validation Loss = 0.0792, Validation Accuracy = 0.9802\n",
      "3937/3937 [==============================] - 1333s 338ms/step - loss: 0.0799 - accuracy: 0.9804 - val_loss: 0.0792 - val_accuracy: 0.9802\n",
      "Epoch 8/30\n",
      "3937/3937 [==============================] - ETA: 0s - loss: 0.0676 - accuracy: 0.9836Epoch 8: Training Loss = 0.0676, Training Accuracy = 0.9836, Validation Loss = 0.0750, Validation Accuracy = 0.9804\n",
      "3937/3937 [==============================] - 1382s 351ms/step - loss: 0.0676 - accuracy: 0.9836 - val_loss: 0.0750 - val_accuracy: 0.9804\n",
      "Epoch 9/30\n",
      "3937/3937 [==============================] - ETA: 0s - loss: 0.0582 - accuracy: 0.9858Epoch 9: Training Loss = 0.0582, Training Accuracy = 0.9858, Validation Loss = 0.0732, Validation Accuracy = 0.9800\n",
      "3937/3937 [==============================] - 1334s 339ms/step - loss: 0.0582 - accuracy: 0.9858 - val_loss: 0.0732 - val_accuracy: 0.9800\n",
      "Epoch 10/30\n",
      "3937/3937 [==============================] - ETA: 0s - loss: 0.0546 - accuracy: 0.9868Epoch 10: Training Loss = 0.0546, Training Accuracy = 0.9868, Validation Loss = 0.0712, Validation Accuracy = 0.9812\n",
      "3937/3937 [==============================] - 1381s 351ms/step - loss: 0.0546 - accuracy: 0.9868 - val_loss: 0.0712 - val_accuracy: 0.9812\n",
      "Epoch 11/30\n",
      "3937/3937 [==============================] - ETA: 0s - loss: 0.0513 - accuracy: 0.9876Epoch 11: Training Loss = 0.0513, Training Accuracy = 0.9876, Validation Loss = 0.0677, Validation Accuracy = 0.9814\n",
      "3937/3937 [==============================] - 1367s 347ms/step - loss: 0.0513 - accuracy: 0.9876 - val_loss: 0.0677 - val_accuracy: 0.9814\n",
      "Epoch 12/30\n",
      "3937/3937 [==============================] - ETA: 0s - loss: 0.0489 - accuracy: 0.9885Epoch 12: Training Loss = 0.0489, Training Accuracy = 0.9885, Validation Loss = 0.0654, Validation Accuracy = 0.9826\n",
      "3937/3937 [==============================] - 1372s 348ms/step - loss: 0.0489 - accuracy: 0.9885 - val_loss: 0.0654 - val_accuracy: 0.9826\n",
      "Epoch 13/30\n",
      "3937/3937 [==============================] - ETA: 0s - loss: 0.0461 - accuracy: 0.9893Epoch 13: Training Loss = 0.0461, Training Accuracy = 0.9893, Validation Loss = 0.0651, Validation Accuracy = 0.9827\n",
      "3937/3937 [==============================] - 1387s 352ms/step - loss: 0.0461 - accuracy: 0.9893 - val_loss: 0.0651 - val_accuracy: 0.9827\n",
      "Epoch 14/30\n",
      "3937/3937 [==============================] - ETA: 0s - loss: 0.0465 - accuracy: 0.9889Epoch 14: Training Loss = 0.0465, Training Accuracy = 0.9889, Validation Loss = 0.0651, Validation Accuracy = 0.9825\n",
      "3937/3937 [==============================] - 1367s 347ms/step - loss: 0.0465 - accuracy: 0.9889 - val_loss: 0.0651 - val_accuracy: 0.9825\n",
      "Epoch 15/30\n",
      "3937/3937 [==============================] - ETA: 0s - loss: 0.0456 - accuracy: 0.9890Epoch 15: Training Loss = 0.0456, Training Accuracy = 0.9890, Validation Loss = 0.0639, Validation Accuracy = 0.9831\n",
      "3937/3937 [==============================] - 1369s 347ms/step - loss: 0.0456 - accuracy: 0.9890 - val_loss: 0.0639 - val_accuracy: 0.9831\n",
      "Epoch 16/30\n",
      "3937/3937 [==============================] - ETA: 0s - loss: 0.0436 - accuracy: 0.9900Epoch 16: Training Loss = 0.0436, Training Accuracy = 0.9900, Validation Loss = 0.0633, Validation Accuracy = 0.9830\n",
      "3937/3937 [==============================] - 1371s 348ms/step - loss: 0.0436 - accuracy: 0.9900 - val_loss: 0.0633 - val_accuracy: 0.9830\n",
      "Epoch 17/30\n",
      "3937/3937 [==============================] - ETA: 0s - loss: 0.0450 - accuracy: 0.9896Epoch 17: Training Loss = 0.0450, Training Accuracy = 0.9896, Validation Loss = 0.0632, Validation Accuracy = 0.9828\n",
      "3937/3937 [==============================] - 1369s 348ms/step - loss: 0.0450 - accuracy: 0.9896 - val_loss: 0.0632 - val_accuracy: 0.9828\n",
      "Epoch 18/30\n",
      "3937/3937 [==============================] - ETA: 0s - loss: 0.0434 - accuracy: 0.9897Epoch 18: Training Loss = 0.0434, Training Accuracy = 0.9897, Validation Loss = 0.0633, Validation Accuracy = 0.9828\n",
      "3937/3937 [==============================] - 1369s 348ms/step - loss: 0.0434 - accuracy: 0.9897 - val_loss: 0.0633 - val_accuracy: 0.9828\n",
      "Epoch 19/30\n",
      "3937/3937 [==============================] - ETA: 0s - loss: 0.0442 - accuracy: 0.9896Epoch 19: Training Loss = 0.0442, Training Accuracy = 0.9896, Validation Loss = 0.0634, Validation Accuracy = 0.9831\n",
      "3937/3937 [==============================] - 1370s 348ms/step - loss: 0.0442 - accuracy: 0.9896 - val_loss: 0.0634 - val_accuracy: 0.9831\n",
      "Epoch 20/30\n",
      "3937/3937 [==============================] - ETA: 0s - loss: 0.0439 - accuracy: 0.9898Epoch 20: Training Loss = 0.0439, Training Accuracy = 0.9898, Validation Loss = 0.0629, Validation Accuracy = 0.9830\n",
      "3937/3937 [==============================] - 1370s 348ms/step - loss: 0.0439 - accuracy: 0.9898 - val_loss: 0.0629 - val_accuracy: 0.9830\n",
      "Epoch 21/30\n",
      "3937/3937 [==============================] - ETA: 0s - loss: 0.0433 - accuracy: 0.9901Epoch 21: Training Loss = 0.0433, Training Accuracy = 0.9901, Validation Loss = 0.0633, Validation Accuracy = 0.9830\n",
      "3937/3937 [==============================] - 1371s 348ms/step - loss: 0.0433 - accuracy: 0.9901 - val_loss: 0.0633 - val_accuracy: 0.9830\n",
      "Epoch 22/30\n",
      "3937/3937 [==============================] - ETA: 0s - loss: 0.0447 - accuracy: 0.9896Epoch 22: Training Loss = 0.0447, Training Accuracy = 0.9896, Validation Loss = 0.0631, Validation Accuracy = 0.9832\n",
      "3937/3937 [==============================] - 1369s 348ms/step - loss: 0.0447 - accuracy: 0.9896 - val_loss: 0.0631 - val_accuracy: 0.9832\n",
      "Epoch 23/30\n",
      "3937/3937 [==============================] - ETA: 0s - loss: 0.0440 - accuracy: 0.9900Epoch 23: Training Loss = 0.0440, Training Accuracy = 0.9900, Validation Loss = 0.0634, Validation Accuracy = 0.9830\n",
      "3937/3937 [==============================] - 1382s 351ms/step - loss: 0.0440 - accuracy: 0.9900 - val_loss: 0.0634 - val_accuracy: 0.9830\n",
      "Epoch 24/30\n",
      "3937/3937 [==============================] - ETA: 0s - loss: 0.0447 - accuracy: 0.9893Epoch 24: Training Loss = 0.0447, Training Accuracy = 0.9893, Validation Loss = 0.0633, Validation Accuracy = 0.9831\n",
      "3937/3937 [==============================] - 1359s 345ms/step - loss: 0.0447 - accuracy: 0.9893 - val_loss: 0.0633 - val_accuracy: 0.9831\n",
      "Epoch 25/30\n",
      "3937/3937 [==============================] - ETA: 0s - loss: 0.0450 - accuracy: 0.9894Epoch 25: Training Loss = 0.0450, Training Accuracy = 0.9894, Validation Loss = 0.0630, Validation Accuracy = 0.9828\n",
      "Early stopping triggered!\n",
      "3937/3937 [==============================] - 1342s 341ms/step - loss: 0.0450 - accuracy: 0.9894 - val_loss: 0.0630 - val_accuracy: 0.9828\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class CustomEarlyStopping(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, patience=7):\n",
    "        super(CustomEarlyStopping, self).__init__()\n",
    "        self.patience = patience\n",
    "        self.best_weights = None\n",
    "        self.best_loss = float('inf')\n",
    "        self.wait = 0\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # Get training and validation accuracy and loss\n",
    "        current_train_acc = logs.get(\"accuracy\")\n",
    "        current_val_acc = logs.get(\"val_accuracy\")\n",
    "        current_train_loss = logs.get(\"loss\")\n",
    "        current_val_loss = logs.get(\"val_loss\")\n",
    "\n",
    "        # Print training and validation loss and accuracy\n",
    "        print(f\"Epoch {epoch + 1}: \"\n",
    "              f\"Training Loss = {current_train_loss:.4f}, Training Accuracy = {current_train_acc:.4f}, \"\n",
    "              f\"Validation Loss = {current_val_loss:.4f}, Validation Accuracy = {current_val_acc:.4f}\")\n",
    "\n",
    "        # Early stopping check\n",
    "        if current_val_loss < self.best_loss:\n",
    "            self.best_loss = current_val_loss\n",
    "            self.best_weights = self.model.get_weights()\n",
    "            self.wait = 0  # reset wait counter if we have a new best loss\n",
    "        else:\n",
    "            self.wait += 1  # increment wait counter if no improvement\n",
    "            if self.wait >= self.patience:\n",
    "                print(\"Early stopping triggered!\")\n",
    "                self.model.stop_training = True\n",
    "                # Restore the best weights if needed\n",
    "                self.model.set_weights(self.best_weights)\n",
    "\n",
    "# Instantiate the callback\n",
    "custom_early_stopping = CustomEarlyStopping(patience=5)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=30,\n",
    "    callbacks=[custom_early_stopping]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1dcbcff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"C:/Users/Research Marshals/Satellite/models/8 classes/EfficiantNet_b3_latest_TRIAL_nw.h5\")  # saves in HDF5 format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f85dd935-130c-4f27-993b-7b6c19c13d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the saved model\n",
    "model_path = \"C:/Users/Research Marshals/Satellite/models/8 classes/EfficiantNet_b3_latest_TRIAL.h5\"\n",
    "loaded_model = load_model(model_path)\n",
    "print(\"Model loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d4e3455-d024-4fc4-80d3-ce6b0d64ddc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "493/493 [==============================] - 26s 49ms/step\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0     0.9834    0.9801    0.9817       905\n",
      "     Class 1     0.9720    0.9739    0.9730       998\n",
      "     Class 2     0.9827    0.9688    0.9757      1057\n",
      "     Class 3     0.9745    0.9663    0.9704       356\n",
      "     Class 4     0.9902    0.9988    0.9945       809\n",
      "     Class 5     0.9817    0.9836    0.9827      1527\n",
      "     Class 6     0.9630    0.9849    0.9738       661\n",
      "     Class 7     0.9942    0.9904    0.9923      1567\n",
      "\n",
      "    accuracy                         0.9822      7880\n",
      "   macro avg     0.9802    0.9809    0.9805      7880\n",
      "weighted avg     0.9823    0.9822    0.9822      7880\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Get true labels and predictions\n",
    "y_true = np.concatenate([y.numpy() for _, y in test_ds], axis=0)\n",
    "y_pred_probs = loaded_model.predict(test_ds)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "# Compute precision, recall, and F1-score\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_true, y_pred, target_names=[f\"Class {i}\" for i in range(num_classes)], digits=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "120773ee-0a72-480f-9164-25f87390e328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "efficientnetb3\n",
      "batch_normalization_1\n",
      "global_average_pooling2d_1\n",
      "dense_2\n",
      "dropout_1\n",
      "dense_3\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    print(layer.name)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
